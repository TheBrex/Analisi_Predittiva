---
title: "Lab 03 - Multiple Linear Regression, model assessment"
output:
  html_document:
    theme: readable
    toc: yes
    code_folding: show
---

# The data

Usiamo i dati di automobili visti nel lab precedente: leggiamo direttamente i dati usando il file in Moodle:

```{r}
autompg <- read.csv(file = "datasets/autompg.csv")
```

Abbiamo 7 variabili: una variabile risposta (`mpg`) e 6 predittori:

```{r dataplot}
## use rgb to define proportion of reg-green-blue in a color
## extra 4th argument is alpha - the transparency of the points 
par(col= rgb(0.4,0.4,0.9,0.8),pch=16)
plot(autompg)
```

Presi individualemnte alcuni predittori sembrano essere più o meno correlati con la variabile risposta:

```{r}
signif(cor(autompg),3)
```

Dovremo individuare un sottoinsieme di predittori utili a costruire un modello predittivo per `mpg` (vediamo inoltre che i predittori sono anche correlati tra loro).

# Specificazione del modello

Specifichiamo un modello con due predittori `hp` e `year`:

$$
Y_i = \beta_0 + \beta_{hp} \text{hp}_{i} + \beta_{year} \text{year}_{i} + \epsilon_i, \qquad i = 1, 2, \ldots, n
$$ con $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$ (errori indipendenti).

```{r, class.source = "fold-show"}
fit1 <- lm(mpg~hp+year, data = autompg)
fit_null<-lm(mpg~1, data=autompg)#modello nullo
```

Questo modello è significativo?? Vogliamo vedere se è significativo contro il modello nullo

```{r}
summary(fit1)

```

$$
H_0: \beta_{hp} = \beta_{year} = 0
$$

```{r}
anova(fit_null, fit1)
```

L'analisi della statistica fit ha un elevato valore e un p-value molto piccolo, questo significa che c'è significatività contro il l'ipotesi nulla, il p value mi dice quantà probabilità si adndrebbe a distribuire sulle code della distribuzione

```{r}
sum(residuals(fit_null)^2)
sum(residuals(fit1)^2)
sum(residuals(fit_null)^2)- sum(residuals(fit1)^2)
sum((fitted(fit_null)-fitted(fit1))^2)

fit1$df.residual-fit_null$df.residual #mi dice la differenza tra i gradi di libertà usati da fit null e fit1
num <- (sum(residuals(fit_null)^2)- sum(residuals(fit1)^2))/ (fit_null$df.residual-fit1$df.residual)
den <-sum(residuals(fit1)^2) / fit1$df.residual
(fobs<-num/den)

#pvalue
pf(fobs, df1=(fit_null$df.residual - fit1$df.residual), df2=fit1$df.residual, lower.tail = FALSE)#0

```

```{r}
summary(fit1)$fstatistic
```

```{r}
fit_base<-lm(mpg~wt+year, data=autompg)
fit_all<-lm(mpg~., data=autompg)

summary(fit_all)
```

Noto che hp preso e inserito in un modello più grande perde tutta la significatività che aveva nel modello fit1

```{r}
sum(residuals(fit_base)^2)
sum(residuals(fit_all)^2)
```

cosa succede se facciamo una stima?

```{r}
nd<-data.frame(apply(autompg, 2, quantile, c(0.1,0.5,0.9)))
ci_all<- predict(fit_all, newdata = nd, interval="conf")
ci_base<-predict(fit_base, newdata = nd, interval="conf")

ci_all[,3]-ci_all[,2] 
ci_base[,3]-ci_base[,2]

```

Gli intervalli di confidenza sono più stretti per il modello fit_all poichè include molti più predittori, offrendo peggiori performance in termini di generalizzazione. Quindi quando avrò un maggiore generalizzazione le possibilità d'errore aumentano e quindi il range sarà più ampio.

```{r}
anova(fit_base,fit_all)
```

La statistica F è piccola rispetto ad una distribuzione F con 383 gradi di libertà

```{r}
num<-(sum(residuals(fit_base)^2)- sum(residuals(fit_all)^2))/(fit_base$df.residuals - fit_all$df.residual)

den<-sum(residuals(fit_all)^2)/fit_all$df.residual
fobs<-num/den
#pvalue
pf(fobs, df1=(fit_base$df.residual- fit_all$df.residual),df2=fit_all$df.residual, lower.tail = FALSE)
#reject H0 if fobs >fcri
qf(.98, df1 = (fit_base$df.residual- fit_all$df.residual), df2=fit_all$df.residual)

curve(df(x, df1 = (fit_base$df.residual - fit_all$df.residual), df2=fit_all$df.residual), from=0, to=10)
points(fobs, 0 , col=2, pch=4)
```

Bontà di adattamento : confronto tra modelli non annidati:

R\*\*2 adj

```{r}
summary(fit_base)$r.square
summary(fit_base)$adj.r.square
1- sum(residuals(fit_base)^2) / (sum((autompg$mpg - mean(autompg$mpg))^2))
1- sum(residuals(fit_base)^2)/(fit_base$df.residual) / (sum((autompg$mpg - mean(autompg$mpg))^2)/fit_null$df.residual)

#N.B correggere formule
```

Criteri di informazione

AIC

```{r}
logLik(fit_base)
sum(dnorm(autompg$mpg, mean=fitted(fit_base), sd=summary(fit_base)$sigma, log=TRUE))

-2*logLik(fit_base)+2*(length(coef(fit_base))+1) #valore di AIC (numero paramentri)
-2*logLik(fit_all)+2*(length(coef(fit_all))+1) #valore di AIC (numero paramentri)

AIC(fit_base)
AIC(fit_all)
```

BIC

```{r}
-2*logLik(fit_base)+log(nrow(autompg))*(length(coef(fit_base))+1) #valore di BIC (numero paramentri)
-2*logLik(fit_all)+log(nrow(autompg))*(length(coef(fit_all))+1) #valore di BIC (numero paramentri)

BIC(fit_base)
BIC(fit_all)

AIC(fit_base, k=log(nrow(autompg)))
```

Verifica della teoria tramite simulazione

```{r}
X <- model.matrix(fit_base)
colnames(X) <- c("Int", "x1", "x2")
sigma_true<-3.4
beta_true<-c(-14, -0.006, .74)
n <- nrow(X)
#set.seed(8686)
y_alternative<- X %*% beta_true + rnorm(n,0, sigma_true)

autodf_alternative<- data.frame(y= y_alternative, X[,-1])
lm(y~x1+x2, data=autodf_alternative)
```

```{r}
generate_and_estimate <- function(){
  n<-nrow(X)
  y_alternative<- X %*% beta_true + rnorm(n,0, sigma_true)
  autodf_alternative<- data.frame(y= y_alternative, X[,-1])
  estimate<- coef(lm(y~x1+x2, data=autodf_alternative))
  estimate
}

```
